{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNvas8U+Daf6++pdadGAOxd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"H12zgGt46z7H"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","\n","\n"]},{"cell_type":"code","source":["with open(\"alchemist.txt\", 'r', encoding='utf-8') as f:\n","    text = f.read()\n","\n","print(f\"Total characters: {len(text)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2n9ke-3I8N0B","executionInfo":{"status":"ok","timestamp":1752245504699,"user_tz":-345,"elapsed":42,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"44a3c3b6-505d-44ba-df17-134aea104ebd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total characters: 234264\n"]}]},{"cell_type":"code","source":["chars = sorted(set(text))\n","print(len(chars))\n","char2int = {ch: i for i, ch in enumerate(chars)}\n","int2char = {i: ch for i, ch in enumerate(chars)}\n","\n","vocab = len(chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gq0O5koKF4GI","executionInfo":{"status":"ok","timestamp":1752247551837,"user_tz":-345,"elapsed":39,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"3b77a2fa-05d2-4179-c553-cd1da6b324e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["84\n"]}]},{"cell_type":"code","source":["chars = sorted(set(text))\n","char2int = {ch: i for i, ch in enumerate(chars)}\n","int2char = {i: ch for i, ch in enumerate(chars)}\n","\n","data_encoded = np.array([char2int[ch] for ch in text], dtype=np.int64)\n","\n","class TextDataset(Dataset):\n","  def __init__(self, data, seq_length):\n","    self.data = data\n","    self.seq_length = seq_length\n","\n","  def __len__(self):\n","    return len(self.data) - self.seq_length\n","\n","\n","  def __getitem__(self, idx):\n","    x = self.data[idx: idx+self.seq_length]\n","    y = self.data[idx+self.seq_length]\n","    x = torch.tensor(x, dtype=torch.long)\n","    y = torch.tensor(y, dtype=torch.long)\n","    return x, y\n","\n","\n","split = int(len(data_encoded)*0.8)\n","\n","train_dataset = data_encoded[:split]\n","test_dataset = data_encoded[split:]\n","\n","seq_len = 100\n","batch_size = 64\n","embed_size = 128\n","hidden_size = 256\n","num_layers = 2\n","\n","train_dataset = TextDataset(train_dataset, seq_len)\n","test_dataset = TextDataset(test_dataset, seq_len)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n","\n","\n","\n","class CharRNN(nn.Module):\n","  def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n","    super().__init__()\n","    self.embedding = nn.Embedding(vocab_size, embed_size)\n","    self.rnn = nn.RNN(input_size=embed_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n","    self.fc = nn.Linear(hidden_size, vocab_size)\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","\n","  def forward(self, x, hidden):\n","    emb = self.embedding(x) # [batch, seq] -> [batch, seq, embed_dim]\n","    out, hidden = self.rnn(emb, hidden) # out: [batch, seq, hidden]\n","    last = out[:, -1, :] # [batch, hidden]\n","    logits = self.fc(last)\n","    return logits, hidden\n","\n","  def init_hidden(self, batch_size):\n","    return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = CharRNN(vocab_size=vocab, embed_size=embed_size, hidden_size=hidden_size, num_layers=num_layers).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","epochs = 50\n","\n","model.train()\n","for epoch in range(1, epochs+1):\n","  hidden = model.init_hidden(batch_size).to(device)\n","  total_loss = 0\n","  for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n","    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","    optimizer.zero_grad()\n","    hidden = hidden.detach()\n","    logits, hidden = model(x_batch, hidden)\n","    loss = criterion(logits, y_batch)\n","    loss.backward()\n","    optimizer.step()\n","    total_loss += loss.item()\n","\n","  print(f\"Epoch: {epoch}, Loss: {total_loss/len(train_loader)}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":948},"id":"DkunuXYU-Hji","executionInfo":{"status":"error","timestamp":1752251307511,"user_tz":-345,"elapsed":603554,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"1c3e940b-ea42-44d3-b6c1-4b4ecffa7cd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss: 1.7363349864398137\n","Epoch: 2, Loss: 1.4310169286175451\n","Epoch: 3, Loss: 1.3499434082090895\n","Epoch: 4, Loss: 1.3069081218659837\n","Epoch: 5, Loss: 1.2812589695212455\n","Epoch: 6, Loss: 1.261522964997725\n","Epoch: 7, Loss: 1.246847966254287\n","Epoch: 8, Loss: 1.2377779281514194\n","Epoch: 9, Loss: 1.2309103346979138\n","Epoch: 10, Loss: 1.2254305899306184\n","Epoch: 11, Loss: 1.223903723290255\n","Epoch: 12, Loss: 1.2208295333532138\n","Epoch: 13, Loss: 1.2198815440895292\n","Epoch: 14, Loss: 1.2233406751023852\n","Epoch: 15, Loss: 1.2237478244695774\n","Epoch: 16, Loss: 1.223607191526963\n","Epoch: 17, Loss: 1.2306933001508797\n","Epoch: 18, Loss: 1.2270532797764853\n","Epoch: 19, Loss: 1.2278762900780424\n","Epoch: 20, Loss: 1.2365187760582543\n","Epoch: 21, Loss: 1.23674705583839\n","Epoch: 22, Loss: 1.2406139169664963\n","Epoch: 23, Loss: 1.2430092484390418\n","Epoch: 24, Loss: 1.2463172797829178\n","Epoch: 25, Loss: 1.2476508680753975\n","Epoch: 26, Loss: 1.2526990157932105\n","Epoch: 27, Loss: 1.2564218661920388\n","Epoch: 28, Loss: 1.2645069653459877\n","Epoch: 29, Loss: 1.267439254998183\n","Epoch: 30, Loss: 1.266312358237584\n","Epoch: 31, Loss: 1.2767403291987787\n","Epoch: 32, Loss: 1.278693207285621\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-43-1930119884.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-43-1930119884.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Text generate\n","def generated_text(model, start_text, length):\n","  model.eval()\n","  chars = [ch for ch in start_text]\n","  input_vector = torch.tensor([char2int[ch] for ch in chars], dtype=torch.long).unsqueeze(0).to(device)\n","  hidden = model.init_hidden(1).to(device)\n","  with torch.no_grad():\n","    for i in range(len(start_text)-1):\n","      logits, hidden = model(input_vector[:, i:i+1], hidden)\n","    last_char = input_vector[:, -1]\n","\n","\n","    for i in range(length):\n","      logits, hidden = model(last_char.unsqueeze(0), hidden) # logits-> (batch, seq, vocab_size)\n","      probs = torch.softmax(logits.squeeze(), dim=0)\n","      probs = probs.cpu().numpy()\n","      next_idx = np.random.choice(len(probs), p=probs)\n","      # next_idx = torch.argmax(probs).item()\n","\n","      next_char = int2char[next_idx]\n","      chars.append(next_char)\n","      last_char = torch.tensor([next_idx], dtype=torch.long).to(device)\n","\n","  return ''.join(chars)\n","\n","\n","text = 'Maktub,” the boy said, remembering the'\n","generated = generated_text(model, text, 500)\n","print(\"Generated_text: \", generated)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36KUgl0zR0Ll","executionInfo":{"status":"ok","timestamp":1752252799721,"user_tz":-345,"elapsed":386,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"6151b2f5-9ae6-4944-baf8-cc0d565d851e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated_text:  Maktub,” the boy said, remembering the sentir Gourees, two concerned and maybe things who translated the sact: untill be\n"," soullowing enemoeled in the boy in lased he had treasured\n"," asked. He a moment. The ensipe and try alchemy. But the old king a day. The boy\n","way beginnest when\n"," the oasis. He said pike, and alrept of the alchemist, and some do the boy\n"," this it\n"," had stay\n"," paying divall traity. The boy had as the boy knew the basis, had being on the vision. He had deal outed palm of every time the awpended that thought there camable \n"]}]},{"cell_type":"code","source":["probs = [0.1, 0.3, 0.6]\n","for i in range(10):\n","  next_idx = np.random.choice(len(probs), p=probs)\n","  print(next_idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C6xzQ3MKaMQ5","executionInfo":{"status":"ok","timestamp":1752252967682,"user_tz":-345,"elapsed":52,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"85f51e20-5489-42eb-b285-9e58a4064481"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","0\n","2\n","2\n","0\n","2\n","2\n","2\n","1\n","1\n"]}]},{"cell_type":"code","source":["x = torch.tensor([[[1,2,3,4,5]]], dtype=torch.float32)\n","x = x.squeeze()\n","x\n","probs = torch.softmax(x, dim=0)\n","probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WqN6fgwXljj","executionInfo":{"status":"ok","timestamp":1752252375518,"user_tz":-345,"elapsed":91,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"42acf471-82fa-4b6d-9e1a-2ac6ea28b227"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0117, 0.0317, 0.0861, 0.2341, 0.6364])"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["input_vector = torch.tensor([1.0,2.0, 3.0])\n","input_vector.unsqueeze(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ka9wRjhU18U","executionInfo":{"status":"ok","timestamp":1752251490079,"user_tz":-345,"elapsed":15,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"692cff67-a435-4903-efbf-56d72a5f030b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 2., 3.]])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["for batch_x, batch_y in train_loader:\n","  print(batch_x.shape, batch_y.shape)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"Hv4QE3CSQvva","executionInfo":{"status":"error","timestamp":1752250417285,"user_tz":-345,"elapsed":71,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"65ddcd60-41da-4abd-a299-9583846b9d21"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-36-4151717433.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"qtIOCwZdQvgu"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itRMoqovNHF4","executionInfo":{"status":"ok","timestamp":1752249435571,"user_tz":-345,"elapsed":36,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"f5e83ea2-fc7a-4fe1-b22a-7bcbf3027053"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["chars"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Elwq-ulAG9Qm","executionInfo":{"status":"ok","timestamp":1752247820438,"user_tz":-345,"elapsed":27,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"18ab83b5-165c-49c4-92b2-71da07b187e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['\\n',\n"," ' ',\n"," '!',\n"," '(',\n"," ')',\n"," ',',\n"," '-',\n"," '.',\n"," '/',\n"," '0',\n"," '1',\n"," '2',\n"," '3',\n"," '4',\n"," '5',\n"," '6',\n"," '7',\n"," '8',\n"," '9',\n"," ':',\n"," ';',\n"," '?',\n"," 'A',\n"," 'B',\n"," 'C',\n"," 'D',\n"," 'E',\n"," 'F',\n"," 'G',\n"," 'H',\n"," 'I',\n"," 'J',\n"," 'K',\n"," 'L',\n"," 'M',\n"," 'N',\n"," 'O',\n"," 'P',\n"," 'R',\n"," 'S',\n"," 'T',\n"," 'U',\n"," 'V',\n"," 'W',\n"," 'X',\n"," 'Y',\n"," 'Z',\n"," 'a',\n"," 'b',\n"," 'c',\n"," 'd',\n"," 'e',\n"," 'f',\n"," 'g',\n"," 'h',\n"," 'i',\n"," 'j',\n"," 'k',\n"," 'l',\n"," 'm',\n"," 'n',\n"," 'o',\n"," 'p',\n"," 'q',\n"," 'r',\n"," 's',\n"," 't',\n"," 'u',\n"," 'v',\n"," 'w',\n"," 'x',\n"," 'y',\n"," 'z',\n"," '©',\n"," '®',\n"," 'á',\n"," 'é',\n"," '–',\n"," '—',\n"," '‘',\n"," '’',\n"," '“',\n"," '”',\n"," '™']"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["embeddings = nn.Embedding(5, 10)\n","print(embeddings.weight)\n","\n","input_tokens = torch.tensor([0,1,2])\n","output = embeddings(input_tokens)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccTfzVK-GSki","executionInfo":{"status":"ok","timestamp":1752247923674,"user_tz":-345,"elapsed":58,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"38cb7968-73a2-4ac1-da9c-4be1ff049377"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[ 0.9895, -0.7138,  1.5428, -0.5540,  0.5835,  0.7710, -0.2709, -0.5589,\n","          0.1004,  2.6170],\n","        [-2.2132, -0.8640, -0.7878,  1.1469,  1.7457,  0.1805,  0.2211, -0.3021,\n","          2.2576,  3.6529],\n","        [-0.8738, -1.1644,  1.5557,  1.6027,  0.2543, -0.4666,  0.5439, -0.4019,\n","          1.6052, -0.2464],\n","        [-0.2778,  0.2834, -0.1060,  1.9152,  0.9526,  0.3398,  0.2784, -0.4145,\n","          0.1950,  0.5672],\n","        [ 0.9513, -0.1135,  0.7616,  0.6755, -1.0950, -2.0004,  0.2955, -1.7610,\n","          0.5836,  1.0470]], requires_grad=True)\n","tensor([[ 0.9895, -0.7138,  1.5428, -0.5540,  0.5835,  0.7710, -0.2709, -0.5589,\n","          0.1004,  2.6170],\n","        [-2.2132, -0.8640, -0.7878,  1.1469,  1.7457,  0.1805,  0.2211, -0.3021,\n","          2.2576,  3.6529],\n","        [-0.8738, -1.1644,  1.5557,  1.6027,  0.2543, -0.4666,  0.5439, -0.4019,\n","          1.6052, -0.2464]], grad_fn=<EmbeddingBackward0>)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9P1R2uvfGRw-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"itFSNsT0_ZE3","executionInfo":{"status":"ok","timestamp":1752245838287,"user_tz":-345,"elapsed":81,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"b77d9046-f20a-49af-ae2b-930f99fae363"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Contents\\n International Acclaim for Paulo Coelho’s\\n Foreword\\n Prologu\\n e\\n Part One\\n Part Two\\n Epilogue\\n A Preview of Paulo Coelho’s: Warrior of the Light\\n Warrior of the Light: Prologue\\n About the Author\\n Also by Paulo Coelho\\n Back Ads\\n Copyright\\n About the Publisher\\nInternational Acclaim for Paulo Coelho’s\\n THE ALCHEMIST\\n “The story has the comic charm, dramatic tension, and psychological\\n intensity of a fairy tale, but it’s full of specific wisdom as well. . . . A\\n sweetly exotic tale for youn'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["chars = sorted(set(\"apple ball cat\"))\n","chars"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LsepNJXv8oCe","executionInfo":{"status":"ok","timestamp":1752245278671,"user_tz":-345,"elapsed":55,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"766392f9-9ec0-4574-b682-d6a2793aba14"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' ', 'a', 'b', 'c', 'e', 'l', 'p', 't']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["char2int = {ch: i for i, ch in enumerate(chars)}\n","char2int"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7LQ_5bB_9R62","executionInfo":{"status":"ok","timestamp":1752245312585,"user_tz":-345,"elapsed":66,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"46c6f9cf-c59c-4888-c0b1-6932053c04b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'e': 4, 'l': 5, 'p': 6, 't': 7}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["text = 'apple ball cat'\n","index = [char2int[ch] for ch in text]\n","index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIRTRwhQ9jT6","executionInfo":{"status":"ok","timestamp":1752245408076,"user_tz":-345,"elapsed":41,"user":{"displayName":"Saurab Baral","userId":"16294404769296255441"}},"outputId":"c7f3b4d8-3577-4ae8-f59d-485edb960078"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 6, 6, 5, 4, 0, 2, 1, 5, 5, 0, 3, 1, 7]"]},"metadata":{},"execution_count":10}]}]}